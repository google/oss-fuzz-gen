"language": "c++"
"project": "llamacpp"
"target_name": "fuzz_grammar"
"target_path": "/src/llama.cpp/fuzzers/fuzz_grammar.cpp"
"test_files":
- "test_file_path": "/src/llama.cpp/tests/test-quantize-fns.cpp"
- "test_file_path": "/src/llama.cpp/examples/infill/infill.cpp"
- "test_file_path": "/src/llama.cpp/examples/lookup/lookup-create.cpp"
- "test_file_path": "/src/llama.cpp/examples/llava/llava-cli.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-tokenizer-0.cpp"
- "test_file_path": "/src/llama.cpp/examples/tokenize/tokenize.cpp"
- "test_file_path": "/src/llama.cpp/examples/retrieval/retrieval.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-quantize-perf.cpp"
- "test_file_path": "/src/llama.cpp/examples/baby-llama/baby-llama.cpp"
- "test_file_path": "/src/llama.cpp/examples/gguf-split/gguf-split.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-log.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-json-schema-to-grammar.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-tokenizer-1-bpe.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-tokenizer-1-spm.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-rope.cpp"
- "test_file_path": "/src/llama.cpp/examples/quantize-stats/quantize-stats.cpp"
- "test_file_path": "/src/llama.cpp/examples/perplexity/perplexity.cpp"
- "test_file_path": "/src/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c"
- "test_file_path": "/src/llama.cpp/examples/llava/minicpmv-cli.cpp"
- "test_file_path": "/src/llama.cpp/examples/parallel/parallel.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-barrier.cpp"
- "test_file_path": "/src/llama.cpp/tests/test-c.c"
- "test_file_path": "/src/llama.cpp/tests/test-autorelease.cpp"
- "test_file_path": "/src/llama.cpp/examples/llama-bench/llama-bench.cpp"
- "test_file_path": "/src/llama.cpp/examples/gguf-hash/deps/sha256/sha256.c"
