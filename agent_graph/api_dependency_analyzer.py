#!/usr/bin/env python3
"""
API Dependency Analyzer - åŸºäº Tree-sitter å’Œ FuzzIntrospector

ä»ç°æœ‰çš„ tree-sitter å’Œ FuzzIntrospector åŸºç¡€è®¾æ–½æ„å»º API ä¾èµ–å›¾ï¼Œ
ç”¨äºæŒ‡å¯¼ LLM ç”Ÿæˆæ­£ç¡®çš„ API è°ƒç”¨åºåˆ—ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è¯†åˆ«å‰ç½®ä¾èµ–ï¼ˆåˆå§‹åŒ–å‡½æ•°ï¼‰
2. åˆ†ææ•°æ®æµä¾èµ–ï¼ˆå‚æ•°æ¥æºï¼‰
3. æ„å»ºè°ƒç”¨å›¾
4. ç”Ÿæˆæ­£ç¡®çš„è°ƒç”¨é¡ºåº

ä½¿ç”¨æ–¹æ³•ï¼š
    from agent_graph.api_dependency_analyzer import APIDependencyAnalyzer
    
    analyzer = APIDependencyAnalyzer(
        project_name="igraph",
        project_dir="/path/to/src"
    )
    
    dep_graph = analyzer.build_dependency_graph("target_function")
    print(dep_graph["call_sequence"])  # æ­£ç¡®çš„è°ƒç”¨é¡ºåº
"""

import logging
import re
from typing import Dict, List, Optional, Set, Tuple
from data_prep import introspector
from agent_graph.api_context_extractor import APIContextExtractor
from agent_graph.api_heuristics import (
    INIT_SUFFIXES,
    CLEANUP_SUFFIXES,
    clean_type_name,
    is_primitive_type,
    get_base_name_from_type
)

# å°è¯•å¯¼å…¥ networkx
try:
    import networkx as nx
    HAS_NETWORKX = True
except ImportError:
    HAS_NETWORKX = False
    # Fallback: ä½¿ç”¨ç®€å•çš„é‚»æ¥è¡¨
    class SimpleGraph:
        """ç®€å•çš„æœ‰å‘å›¾å®ç°ï¼ˆæ—  networkx æ—¶çš„ fallbackï¼‰"""
        def __init__(self):
            self.nodes = {}
            self.edges = []
        
        def add_node(self, node, **attrs):
            self.nodes[node] = attrs
        
        def add_edge(self, src, dst, **attrs):
            self.edges.append((src, dst, attrs))
        
        def get_nodes(self):
            return list(self.nodes.keys())
        
        def topological_sort_dfs(self):
            """ç®€å•çš„æ‹“æ‰‘æ’åºå®ç°"""
            # æ„å»ºé‚»æ¥è¡¨
            graph = {}
            in_degree = {}
            for node in self.nodes:
                graph[node] = []
                in_degree[node] = 0
            
            for src, dst, _ in self.edges:
                graph[src].append(dst)
                in_degree[dst] = in_degree.get(dst, 0) + 1
            
            # Kahn's algorithm
            queue = [n for n in self.nodes if in_degree[n] == 0]
            result = []
            
            while queue:
                node = queue.pop(0)
                result.append(node)
                for neighbor in graph[node]:
                    in_degree[neighbor] -= 1
                    if in_degree[neighbor] == 0:
                        queue.append(neighbor)
            
            return result if len(result) == len(self.nodes) else list(self.nodes.keys())

logger = logging.getLogger(__name__)


class APIDependencyAnalyzer:
    """
    åŸºäºç°æœ‰çš„ tree-sitter + FuzzIntrospector æ„å»ºä¾èµ–å›¾
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. Heuristic mode (é»˜è®¤): ä½¿ç”¨å¯å‘å¼è§„åˆ™å¿«é€Ÿåˆ†æ
    2. LLM mode: ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æï¼ˆéœ€è¦æä¾› llm å‚æ•°ï¼‰
    """
    
    def __init__(
        self, 
        project_name: str, 
        project_dir: str = "",
        llm: Optional[any] = None,
        use_llm: bool = False
    ):
        self.project_name = project_name
        self.project_dir = project_dir
        self.llm = llm
        self.use_llm = use_llm and llm is not None
        
        # ä½¿ç”¨ networkx æˆ– fallback
        if HAS_NETWORKX:
            self.graph = nx.DiGraph()
        else:
            self.graph = SimpleGraph()
            logger.warning("networkx not available, using simple graph implementation")
        
        self.extractor = APIContextExtractor(project_name)
        self._all_functions_cache: Optional[Set[str]] = None
        
        # Initialize LLM analyzer if requested
        self._llm_analyzer = None
        if self.use_llm:
            self._initialize_llm_analyzer()
    
    def _initialize_llm_analyzer(self):
        """åˆå§‹åŒ– LLM åˆ†æå™¨"""
        try:
            from agent_graph.llm_api_analyzer import LLMAPIDependencyAnalyzer, load_prompts
            
            system_prompt, user_prompt_template = load_prompts()
            self._llm_analyzer = LLMAPIDependencyAnalyzer(
                project_name=self.project_name,
                llm=self.llm,
                system_prompt=system_prompt,
                user_prompt_template=user_prompt_template
            )
            logger.info(f"âœ¨ LLM-based API dependency analysis enabled")
        except Exception as e:
            logger.warning(f"Failed to initialize LLM analyzer: {e}. Falling back to heuristics.")
            self.use_llm = False
    
    def build_dependency_graph(self, target_function: str) -> Dict:
        """
        æ„å»ºç›®æ ‡å‡½æ•°çš„å±€éƒ¨ä¾èµ–å›¾
        
        Args:
            target_function: ç›®æ ‡å‡½æ•°åï¼ˆå¦‚ "igraph_sparsemat_arpack_rssolve"ï¼‰
        
        Returns:
            åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
            - prerequisites: å¿…é¡»å…ˆè°ƒç”¨çš„åˆå§‹åŒ–å‡½æ•°åˆ—è¡¨
            - data_dependencies: å‚æ•°ä¾èµ–å…³ç³» [(producer, consumer), ...]
            - call_sequence: æ¨èçš„è°ƒç”¨é¡ºåº
            - initialization_code: å»ºè®®çš„åˆå§‹åŒ–ä»£ç æ¨¡æ¿
            - llm_metadata: (if LLM mode) é¢å¤–çš„ LLM åˆ†æä¿¡æ¯
            
        Note: 
            The internal DiGraph object is not included in the result to avoid
            serialization issues with LangGraph's msgpack checkpointer.
        """
        logger.info(f"Building dependency graph for {target_function}")
        
        # Use LLM analysis if enabled
        if self.use_llm and self._llm_analyzer:
            return self._build_with_llm(target_function)
        
        # Otherwise use heuristic approach
        # 1. ä½¿ç”¨ FuzzIntrospector è·å–å‡½æ•°ä¸Šä¸‹æ–‡
        context = self.extractor.extract(target_function)
        if not context:
            logger.warning(f"Could not extract context for {target_function}")
            return {
                'prerequisites': [],
                'data_dependencies': [],
                'call_sequence': [],
                'initialization_code': []
            }
        
        # 2. è¯†åˆ«å‰ç½®ä¾èµ–ï¼ˆinit å‡½æ•°ï¼‰
        prerequisites = self._find_prerequisite_functions(target_function, context)
        
        # 3. è¯†åˆ«æ•°æ®æµä¾èµ–ï¼ˆå‚æ•°æ¥æºï¼‰
        data_deps = self._analyze_data_dependencies(target_function, context)
        
        # 4. æ„å»ºå›¾
        self.graph.add_node(target_function, type='target', context=context)
        for prereq in prerequisites:
            self.graph.add_node(prereq, type='prerequisite')
            self.graph.add_edge(prereq, target_function, type='control')
        
        for src, dst in data_deps:
            self.graph.add_node(src, type='producer')
            self.graph.add_edge(src, dst, type='data')
        
        # 5. ç”Ÿæˆè°ƒç”¨é¡ºåº
        call_sequence = self._generate_call_sequence()
        
        # 6. ç”Ÿæˆåˆå§‹åŒ–ä»£ç æ¨¡æ¿
        init_code = self._generate_initialization_code(target_function, context, prerequisites)
        
        logger.info(
            f"Dependency graph built: {len(prerequisites)} prerequisites, "
            f"{len(data_deps)} data deps, sequence: {call_sequence}"
        )
        
        return {
            'prerequisites': prerequisites,
            'data_dependencies': data_deps,
            'call_sequence': call_sequence,
            'initialization_code': init_code
        }
    
    def _build_with_llm(self, target_function: str) -> Dict:
        """
        ä½¿ç”¨ LLM æ„å»ºä¾èµ–å›¾ï¼ˆå¢å¼ºæ¨¡å¼ï¼‰
        
        This provides richer, more context-aware dependency analysis
        by leveraging LLM reasoning over cross-references and usage patterns.
        """
        logger.info(f"ğŸ¤– Using LLM-based analysis for {target_function}")
        
        # Get LLM analysis (may return None on failure)
        llm_analysis = self._llm_analyzer.analyze_dependencies(target_function)
        
        if not llm_analysis:
            logger.warning("LLM analysis failed, falling back to heuristics")
            self.use_llm = False  # Disable for subsequent calls
            return self.build_dependency_graph(target_function)
        
        # Convert to legacy format
        result = self._llm_analyzer.convert_to_legacy_format(llm_analysis, target_function)
        
        # Log confidence note if available
        if confidence_note := result.get('llm_metadata', {}).get('confidence_note'):
            logger.info(f"ğŸ” {confidence_note}")
        
        return result
    
    def _find_prerequisite_functions(
        self, 
        func: str, 
        context: Dict
    ) -> List[str]:
        """
        ä½¿ç”¨å¯å‘å¼è§„åˆ™ + FuzzIntrospector æŸ¥æ‰¾å¿…é¡»å…ˆè°ƒç”¨çš„åˆå§‹åŒ–å‡½æ•°
        """
        prerequisites = []
        
        # ä» initialization_patterns ä¸­æå–
        for pattern in context.get('initialization_patterns', []):
            param_type = pattern['type']
            base_name = get_base_name_from_type(param_type)
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ base_name_init/create/new
            for suffix in INIT_SUFFIXES:
                init_func = base_name + suffix
                if self._function_exists(init_func):
                    prerequisites.append(init_func)
                    logger.debug(f"Found prerequisite: {init_func} for type {param_type}")
                    break
        
        # ä» related_functions ä¸­æå–
        for related in context.get('related_functions', []):
            if related['type'] == 'initialization':
                func_name = related['name']
                if func_name not in prerequisites:
                    prerequisites.append(func_name)
        
        return prerequisites
    
    def _analyze_data_dependencies(
        self, 
        func: str, 
        context: Dict
    ) -> List[Tuple[str, str]]:
        """
        åˆ†æå“ªäº›å‚æ•°å¿…é¡»æ¥è‡ªå…¶ä»–å‡½æ•°çš„è¿”å›å€¼
        
        ç­–ç•¥ï¼š
        1. å¯¹äºå¤æ‚ç±»å‹ï¼ˆéåŸºæœ¬ç±»å‹ï¼‰ï¼ŒæŸ¥æ‰¾ç”Ÿäº§è€…å‡½æ•°
        2. ä½¿ç”¨ FuzzIntrospector çš„ç±»å‹ä¿¡æ¯
        """
        deps = []
        
        for param in context.get('parameters', []):
            param_type = clean_type_name(param['type'])
            param_name = param['name']
            
            # è·³è¿‡åŸºæœ¬ç±»å‹
            if is_primitive_type(param_type):
                continue
            
            # æŸ¥æ‰¾ç”Ÿäº§è€…å‡½æ•°ï¼ˆè¿”å›è¯¥ç±»å‹çš„å‡½æ•°ï¼‰
            producer = self._find_producer_function(param_type)
            if producer:
                deps.append((producer, func))
                logger.debug(f"Found data dependency: {producer} -> {func} (type: {param_type})")
        
        return deps
    
    def _find_producer_function(self, type_name: str) -> Optional[str]:
        """
        æŸ¥æ‰¾è¿”å›ç»™å®šç±»å‹çš„å‡½æ•°ï¼ˆé€šå¸¸æ˜¯æ„é€ å™¨ï¼‰
        
        å¯å‘å¼è§„åˆ™ï¼š
        1. base_name_create/new/alloc
        2. æŸ¥è¯¢ FuzzIntrospector è·å–è¿”å›è¯¥ç±»å‹çš„å‡½æ•°
        """
        base = get_base_name_from_type(type_name)
        
        # è§„åˆ™ 1: å¸¸è§çš„æ„é€ å™¨å‘½åæ¨¡å¼
        for suffix in INIT_SUFFIXES:
            candidate = base + suffix
            if self._function_exists(candidate):
                return candidate
        
        # è§„åˆ™ 2: ä½¿ç”¨ FuzzIntrospector æŸ¥è¯¢ï¼ˆå¦‚æœ API æ”¯æŒï¼‰
        # TODO: FuzzIntrospector æœ‰ query_introspector_matching_function_constructor_type
        # ä½†è¿™æ˜¯ä¸º Java è®¾è®¡çš„ï¼Œéœ€è¦æ£€æŸ¥ C/C++ æ”¯æŒ
        
        return None
    
    def _generate_call_sequence(self) -> List[str]:
        """
        æ‹“æ‰‘æ’åºç”Ÿæˆæ­£ç¡®çš„è°ƒç”¨é¡ºåº
        """
        try:
            if HAS_NETWORKX:
                return list(nx.topological_sort(self.graph))
            else:
                return self.graph.topological_sort_dfs()
        except Exception as e:
            logger.warning(f"Topological sort failed: {e}, using simple order")
            # å¦‚æœæœ‰ç¯æˆ–å…¶ä»–é—®é¢˜ï¼Œè¿”å›ç®€å•é¡ºåº
            if HAS_NETWORKX:
                return list(self.graph.nodes())
            else:
                return self.graph.get_nodes()
    
    def _generate_initialization_code(
        self, 
        target_func: str,
        context: Dict, 
        prerequisites: List[str]
    ) -> List[str]:
        """
        ç”Ÿæˆåˆå§‹åŒ–ä»£ç æ¨¡æ¿
        
        Returns:
            ä»£ç ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€è¡Œåˆå§‹åŒ–ä»£ç 
        """
        code_lines = []
        
        if not prerequisites and not context.get('initialization_patterns'):
            return code_lines
        
        code_lines.append("// Initialize required data structures")
        
        # ä¸ºæ¯ä¸ªåˆå§‹åŒ–æ¨¡å¼ç”Ÿæˆä»£ç 
        for pattern in context.get('initialization_patterns', []):
            param_type = pattern['type']
            param_name = pattern['parameter']
            method = pattern.get('method', '')
            
            # ç”Ÿæˆå˜é‡å£°æ˜
            code_lines.append(f"{param_type} {param_name};")
            
            # ç”Ÿæˆåˆå§‹åŒ–è°ƒç”¨
            if method:
                # æ›¿æ¢å ä½ç¬¦
                init_code = method.replace('&var', f'&{param_name}')
                init_code = init_code.replace('var', param_name)
                code_lines.append(init_code + ";")
            else:
                # é»˜è®¤ï¼šä½¿ç”¨ memset
                code_lines.append(f"memset(&{param_name}, 0, sizeof({param_type}));")
        
        # ä¸º prerequisites ç”Ÿæˆè°ƒç”¨
        for prereq in prerequisites:
            code_lines.append(f"// Call prerequisite: {prereq}")
            code_lines.append(f"{prereq}(...);  // TODO: Fill in parameters")
        
        return code_lines
    
    def _ensure_function_cache(self):
        """Lazy load function cache once"""
        if self._all_functions_cache is not None:
            return
        
        try:
            all_funcs = introspector.query_introspector_all_functions(self.project_name)
            # Collect all possible name variations
            names = set()
            for f in all_funcs:
                for key in ['function_signature', 'function-name', 'raw_function_name']:
                    if name := f.get(key):
                        names.add(name)
                        # Also add simple name extracted from signature
                        if '(' in name:
                            simple = re.search(r'\b([a-zA-Z_]\w*)\s*\(', name)
                            if simple:
                                names.add(simple.group(1))
            
            self._all_functions_cache = names
            logger.debug(f"Cached {len(names)} function names")
        except Exception as e:
            logger.debug(f"Could not load function cache: {e}")
            self._all_functions_cache = set()
    
    def _function_exists(self, func_name: str) -> bool:
        """Check if function exists (cached)"""
        self._ensure_function_cache()
        return func_name in self._all_functions_cache


def format_dependency_graph_for_prompt(dep_graph: Dict, target_function: str) -> str:
    """
    å°†ä¾èµ–å›¾æ ¼å¼åŒ–ä¸ºé€‚åˆæ³¨å…¥ prompt çš„æ–‡æœ¬
    
    Args:
        dep_graph: build_dependency_graph() è¿”å›çš„å­—å…¸
        target_function: ç›®æ ‡å‡½æ•°å
    
    Returns:
        æ ¼å¼åŒ–çš„ Markdown æ–‡æœ¬
    """
    if not dep_graph:
        return ""
    
    sections = []
    sections.append("## ğŸ”— API Dependency Analysis\n")
    
    # Check if this is LLM-enhanced analysis
    llm_metadata = dep_graph.get('llm_metadata', {})
    is_llm_enhanced = bool(llm_metadata)
    
    if is_llm_enhanced:
        sections.append("**Source**: LLM-enhanced analysis (high confidence)\n")
        if llm_metadata.get('confidence_note'):
            sections.append(f"**Note**: {llm_metadata['confidence_note']}\n")
    
    # 1. è°ƒç”¨é¡ºåº
    if dep_graph.get('call_sequence'):
        sections.append("### âœ… Recommended Call Sequence\n")
        sections.append("**IMPORTANT**: Follow this order to ensure correct API usage:\n")
        for i, func in enumerate(dep_graph['call_sequence'], 1):
            if func == target_function:
                sections.append(f"{i}. **`{func}`** â† TARGET FUNCTION")
            else:
                sections.append(f"{i}. `{func}`")
        sections.append("")
    
    # 2. å‰ç½®ä¾èµ–ï¼ˆåˆå§‹åŒ–ï¼‰
    if dep_graph.get('prerequisites'):
        sections.append("### âš ï¸ Prerequisites (Initialization)\n")
        sections.append("These functions **MUST** be called before the target function:\n")
        for prereq in dep_graph['prerequisites']:
            sections.append(f"- `{prereq}()` - Initialize required resources")
        sections.append("")
    
    # 3. LLM-enhanced: Configuration functions
    if is_llm_enhanced and llm_metadata.get('configuration_functions'):
        sections.append("### âš™ï¸ Configuration Functions\n")
        sections.append("Use these to configure objects before calling the target:\n")
        for config_func in llm_metadata['configuration_functions']:
            sections.append(f"- `{config_func}()` - Set options/parameters")
        sections.append("")
    
    # 4. LLM-enhanced: Complementary functions
    if is_llm_enhanced and llm_metadata.get('complementary_functions'):
        sections.append("### ğŸ“¤ Complementary Functions (Post-processing)\n")
        sections.append("Consider calling these after the target to query results:\n")
        for comp_func in llm_metadata['complementary_functions']:
            sections.append(f"- `{comp_func}()` - Get status/results")
        sections.append("")
    
    # 5. LLM-enhanced: Cleanup functions
    if is_llm_enhanced and llm_metadata.get('cleanup_functions'):
        sections.append("### ğŸ§¹ Cleanup Functions\n")
        sections.append("Call these to free resources (in reverse order):\n")
        for cleanup_func in llm_metadata['cleanup_functions']:
            sections.append(f"- `{cleanup_func}()` - Free resources")
        sections.append("")
    
    # 6. æ•°æ®ä¾èµ–
    if dep_graph.get('data_dependencies'):
        sections.append("### ğŸ“Š Data Flow Dependencies\n")
        for src, dst in dep_graph['data_dependencies']:
            sections.append(f"- `{src}` produces data consumed by `{dst}`")
        sections.append("")
    
    # 7. åˆå§‹åŒ–ä»£ç æ¨¡æ¿
    if dep_graph.get('initialization_code'):
        sections.append("### ğŸ’¡ Initialization Code Template\n")
        sections.append("```c")
        sections.extend(dep_graph['initialization_code'])
        sections.append("```\n")
    
    # 8. LLM call pattern example (if available)
    if is_llm_enhanced and llm_metadata.get('has_call_pattern'):
        sections.append("### ğŸ“ Complete Usage Pattern\n")
        sections.append("```c")
        # Extract from initialization_code (which contains the call pattern)
        for line in dep_graph.get('initialization_code', []):
            if line.startswith('//'):
                sections.append(line.replace('// ', ''))
        sections.append("```\n")
    
    return "\n".join(sections)


def get_api_dependencies(project_name: str, target_function: str) -> Optional[Dict]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–å‡½æ•°çš„ API ä¾èµ–å›¾
    
    Args:
        project_name: é¡¹ç›®åç§°ï¼ˆå¦‚ "igraph"ï¼‰
        target_function: ç›®æ ‡å‡½æ•°ç­¾å
    
    Returns:
        ä¾èµ–å›¾å­—å…¸ï¼Œå¦‚æœæ„å»ºå¤±è´¥åˆ™è¿”å› None
    """
    try:
        analyzer = APIDependencyAnalyzer(project_name)
        dep_graph = analyzer.build_dependency_graph(target_function)
        return dep_graph if dep_graph['call_sequence'] else None
    except Exception as e:
        logger.error(f"Failed to get API dependencies: {e}", exc_info=True)
        return None


if __name__ == "__main__":
    # æµ‹è¯•
    import sys
    logging.basicConfig(level=logging.DEBUG)
    
    if len(sys.argv) < 3:
        print("Usage: python api_dependency_analyzer.py <project_name> <function_name>")
        sys.exit(1)
    
    project = sys.argv[1]
    func = sys.argv[2]
    
    # è®¾ç½® FuzzIntrospector endpoint
    from data_prep.introspector import set_introspector_endpoints, DEFAULT_INTROSPECTOR_ENDPOINT
    set_introspector_endpoints(DEFAULT_INTROSPECTOR_ENDPOINT)
    
    analyzer = APIDependencyAnalyzer(project)
    result = analyzer.build_dependency_graph(func)
    
    print("\n" + "="*60)
    print(format_dependency_graph_for_prompt(result, func))
    print("="*60)

