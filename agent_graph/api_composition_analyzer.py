#!/usr/bin/env python3
"""
API Composition Analyzer

åˆ†æå¯ä»¥ç»„åˆä¸€èµ·æµ‹è¯•çš„APIï¼Œè€Œä¸æ˜¯APIä¾èµ–å…³ç³»ã€‚
ä»çœŸå®ä½¿ç”¨åœºæ™¯å’Œæ–‡æ¡£ä¸­è¯†åˆ«APIç»„åˆæ¨¡å¼ã€‚
"""

import os
import sys

# Add project root to Python path
_project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

import logging
import re
from typing import Dict, List, Optional, Set, Tuple
from data_prep import introspector
from agent_graph.api_context_extractor import APIContextExtractor
from agent_graph.api_heuristics import (
    INIT_SUFFIXES,
    CLEANUP_SUFFIXES,
    clean_type_name,
    is_primitive_type,
    get_base_name_from_type
)

# å°è¯•å¯¼å…¥ networkx
try:
    import networkx as nx
    HAS_NETWORKX = True
except ImportError:
    HAS_NETWORKX = False
    # Fallback: ä½¿ç”¨ç®€å•çš„é‚»æ¥è¡¨
    class SimpleGraph:
        """ç®€å•çš„æœ‰å‘å›¾å®ç°ï¼ˆæ—  networkx æ—¶çš„ fallbackï¼‰"""
        def __init__(self):
            self.nodes = {}
            self.edges = []
        
        def add_node(self, node, **attrs):
            self.nodes[node] = attrs
        
        def add_edge(self, src, dst, **attrs):
            self.edges.append((src, dst, attrs))
        
        def get_nodes(self):
            return list(self.nodes.keys())
        
        def topological_sort_dfs(self):
            """ç®€å•çš„æ‹“æ‰‘æ’åºå®ç°"""
            # æ„å»ºé‚»æ¥è¡¨
            graph = {}
            in_degree = {}
            for node in self.nodes:
                graph[node] = []
                in_degree[node] = 0
            
            for src, dst, _ in self.edges:
                graph[src].append(dst)
                in_degree[dst] = in_degree.get(dst, 0) + 1
            
            # Kahn's algorithm
            queue = [n for n in self.nodes if in_degree[n] == 0]
            result = []
            
            while queue:
                node = queue.pop(0)
                result.append(node)
                for neighbor in graph[node]:
                    in_degree[neighbor] -= 1
                    if in_degree[neighbor] == 0:
                        queue.append(neighbor)
            
            return result if len(result) == len(self.nodes) else list(self.nodes.keys())

logger = logging.getLogger(__name__)


class APICompositionAnalyzer:
    """
    åˆ†æå¯ä»¥ç»„åˆä¸€èµ·æµ‹è¯•çš„API
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ä»usage examplesä¸­æå–çœŸå®çš„APIç»„åˆæ¨¡å¼ï¼ˆè€Œä¸æ˜¯åŸºäºå‡½æ•°åæ¨¡å¼çŒœæµ‹ï¼‰
    2. è¯†åˆ«å®Œæ•´çš„APIç»„åˆï¼šåŒ…æ‹¬é…ç½®ã€ä½¿ç”¨ã€æ¸…ç†ç­‰ï¼Œè€Œä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°
    3. å‡å°‘å¯å‘å¼è§„åˆ™ä¾èµ–ï¼šåªåœ¨å®Œå…¨æ²¡æœ‰usage examplesæ—¶æ‰ä½¿ç”¨fallback
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. Heuristic mode (é»˜è®¤): åŸºäºçœŸå®ä»£ç ä½¿ç”¨æ¨¡å¼åˆ†æ
    2. LLM mode: ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æï¼ˆéœ€è¦æä¾› llm å‚æ•°ï¼‰
    
    åˆ†æç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä»usage examplesä¸­æå–çœŸå®çš„APIç»„åˆæ¨¡å¼ï¼ˆæœ€å¯é ï¼‰
    2. ä»related_functionsä¸­æå–ï¼ˆä½œä¸ºè¡¥å……ï¼‰
    3. å¯å‘å¼è§„åˆ™ï¼ˆä»…åœ¨å®Œå…¨æ²¡æœ‰usage examplesæ—¶ä½¿ç”¨ï¼Œä½œä¸ºæœ€åæ‰‹æ®µï¼‰
    """
    
    def __init__(
        self, 
        project_name: str, 
        project_dir: str = "",
        llm: Optional['any'] = None,  # Using string literal to avoid import issues
        use_llm: bool = False
    ):
        self.project_name = project_name
        self.project_dir = project_dir
        self.llm = llm
        self.use_llm = use_llm and llm is not None
        
        # ä½¿ç”¨ networkx æˆ– fallback
        if HAS_NETWORKX:
            self.graph = nx.DiGraph()
        else:
            self.graph = SimpleGraph()
            logger.warning("networkx not available, using simple graph implementation")
        
        self.extractor = APIContextExtractor(project_name)
        self._all_functions_cache: Optional[Set[str]] = None
        
        # Initialize LLM analyzer if requested
        self._llm_analyzer = None
        if self.use_llm:
            self._initialize_llm_analyzer()
    
    def _initialize_llm_analyzer(self):
        """åˆå§‹åŒ– LLM åˆ†æå™¨"""
        try:
            from agent_graph.llm_api_analyzer import LLMAPIDependencyAnalyzer
            from agent_graph.prompt_loader import get_prompt_manager
            
            prompt_manager = get_prompt_manager()
            system_prompt = prompt_manager.get_system_prompt("api_dependency_analyzer")
            user_prompt_template = prompt_manager.get_user_prompt_template("api_dependency_analyzer")
            
            self._llm_analyzer = LLMAPIDependencyAnalyzer(
                project_name=self.project_name,
                llm=self.llm,
                system_prompt=system_prompt,
                user_prompt_template=user_prompt_template
            )
            logger.info(f"âœ¨ LLM-based API composition analysis enabled")
        except Exception as e:
            logger.warning(f"Failed to initialize LLM analyzer: {e}. Falling back to heuristics.")
            self.use_llm = False
    
    def find_api_combinations(self, target_function: str, api_context: Optional[Dict] = None) -> Dict:
        """
        æŸ¥æ‰¾å¯ä»¥ä¸ç›®æ ‡å‡½æ•°ç»„åˆä¸€èµ·æµ‹è¯•çš„API
        
        ä¼˜å…ˆä»usage examplesä¸­æå–çœŸå®çš„APIç»„åˆæ¨¡å¼ï¼Œè€Œä¸æ˜¯åŸºäºå‡½æ•°åæ¨¡å¼çš„çŒœæµ‹ã€‚
        è¯†åˆ«å®Œæ•´çš„APIç»„åˆï¼šåŒ…æ‹¬é…ç½®ã€ä½¿ç”¨ã€æ¸…ç†ç­‰ï¼Œè€Œä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°ã€‚
        
        Args:
            target_function: ç›®æ ‡å‡½æ•°åï¼ˆå¦‚ "igraph_sparsemat_arpack_rssolve"ï¼‰
            api_context: (Optional) é¢„å…ˆæå–çš„ API contextï¼Œé¿å…é‡å¤æŸ¥è¯¢ FuzzIntrospector
        
        Returns:
            åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
            - prerequisites: ä¸ç›®æ ‡å‡½æ•°ç»„åˆä½¿ç”¨çš„APIåˆ—è¡¨ï¼ˆä»çœŸå®ä»£ç ä¸­æå–ï¼‰
            - data_dependencies: å‚æ•°ä¾èµ–å…³ç³» [(producer, consumer), ...]
            - call_sequence: æ¨èçš„APIç»„åˆè°ƒç”¨é¡ºåºï¼ˆåŸºäºçœŸå®ä½¿ç”¨åœºæ™¯ï¼‰
            - initialization_code: å»ºè®®çš„åˆå§‹åŒ–ä»£ç æ¨¡æ¿
            - llm_metadata: (if LLM mode) é¢å¤–çš„ LLM åˆ†æä¿¡æ¯
            
        Note: 
            The internal DiGraph object is not included in the result to avoid
            serialization issues with LangGraph's msgpack checkpointer.
        """
        logger.info(f"Finding API combinations for {target_function}")
        
        # Use LLM analysis if enabled
        if self.use_llm and self._llm_analyzer:
            return self._build_with_llm(target_function)
        
        # Otherwise use heuristic approach
        # 1. ä½¿ç”¨ FuzzIntrospector è·å–å‡½æ•°ä¸Šä¸‹æ–‡ï¼ˆæˆ–ä½¿ç”¨æä¾›çš„ api_contextï¼‰
        if api_context:
            logger.debug(f"Using provided api_context (avoiding redundant FI query)")
            context = api_context
        else:
            logger.debug(f"No api_context provided, querying FuzzIntrospector")
            context = self.extractor.extract(target_function)
        
        if not context:
            logger.warning(f"Could not extract context for {target_function}")
            return {
                'prerequisites': [],
                'data_dependencies': [],
                'call_sequence': [],
                'initialization_code': []
            }
        
        # 2. è¯†åˆ«å‰ç½®ä¾èµ–ï¼ˆAPIç»„åˆï¼‰- ä¼˜å…ˆä»usage examplesä¸­æå–çœŸå®ä½¿ç”¨æ¨¡å¼
        prerequisites = self._find_prerequisite_functions(target_function, context)
        
        # 3. è¯†åˆ«æ•°æ®æµä¾èµ–ï¼ˆå‚æ•°æ¥æºï¼‰
        data_deps = self._analyze_data_dependencies(target_function, context)
        
        # 3.5. ä» usage examples ä¸­æå–å®Œæ•´çš„APIç»„åˆè°ƒç”¨åºåˆ—ï¼ˆæ ¸å¿ƒæ”¹è¿›ï¼‰
        # è¿™æå–äº†çœŸå®ä»£ç ä¸­ä¸ç›®æ ‡å‡½æ•°ä¸€èµ·ä½¿ç”¨çš„å®Œæ•´APIé›†åˆ
        usage_call_sequence = self._extract_call_sequence_from_usage_examples(target_function, context)
        if usage_call_sequence:
            logger.info(f"âœ“ Extracted complete API combination sequence from usage examples: {len(usage_call_sequence)} APIs")
        
        # 4. æ„å»ºå›¾
        self.graph.add_node(target_function, type='target', context=context)
        for prereq in prerequisites:
            self.graph.add_node(prereq, type='prerequisite')
            self.graph.add_edge(prereq, target_function, type='control')
        
        for src, dst in data_deps:
            self.graph.add_node(src, type='producer')
            self.graph.add_edge(src, dst, type='data')
        
        # 5. ç”Ÿæˆè°ƒç”¨é¡ºåºï¼ˆä¼˜å…ˆä½¿ç”¨ä» usage examples æå–çš„åºåˆ—ï¼‰
        if usage_call_sequence:
            # ä½¿ç”¨ä» usage examples ä¸­æå–çš„å®Œæ•´åºåˆ—
            call_sequence = usage_call_sequence
            logger.debug(f"Using call sequence from usage examples: {call_sequence}")
        else:
            # Fallback: ä½¿ç”¨æ‹“æ‰‘æ’åº
            call_sequence = self._generate_call_sequence()
        
        # 6. ç”Ÿæˆåˆå§‹åŒ–ä»£ç æ¨¡æ¿
        init_code = self._generate_initialization_code(target_function, context, prerequisites)
        
        logger.info(
            f"API combinations found: {len(prerequisites)} combined APIs, "
            f"{len(data_deps)} data deps, sequence: {call_sequence}"
        )
        
        return {
            'prerequisites': prerequisites,
            'data_dependencies': data_deps,
            'call_sequence': call_sequence,
            'initialization_code': init_code
        }
    
    def _build_with_llm(self, target_function: str) -> Dict:
        """
        ä½¿ç”¨ LLM åˆ†æAPIç»„åˆï¼ˆå¢å¼ºæ¨¡å¼ï¼‰
        
        This provides richer, more context-aware API composition analysis
        by leveraging LLM reasoning over cross-references and usage patterns.
        """
        logger.info(f"ğŸ¤– Using LLM-based analysis for {target_function}")
        
        # Get LLM analysis (may return None on failure)
        llm_analysis = self._llm_analyzer.analyze_dependencies(target_function)
        
        if not llm_analysis:
            logger.warning("LLM analysis failed, falling back to heuristics")
            self.use_llm = False  # Disable for subsequent calls
            return self.find_api_combinations(target_function)
        
        # Convert to legacy format
        result = self._llm_analyzer.convert_to_legacy_format(llm_analysis, target_function)
        
        # Log confidence note if available
        if confidence_note := result.get('llm_metadata', {}).get('confidence_note'):
            logger.info(f"ğŸ” {confidence_note}")
        
        return result
    
    def _find_prerequisite_functions(
        self, 
        func: str, 
        context: Dict
    ) -> List[str]:
        """
        æŸ¥æ‰¾å¿…é¡»ä¸ç›®æ ‡å‡½æ•°ç»„åˆä½¿ç”¨çš„APIé›†åˆ
        
        ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. ä» usage examples ä¸­æå–çœŸå®çš„APIç»„åˆæ¨¡å¼ï¼ˆæœ€å¯é ï¼ŒåŸºäºçœŸå®ä½¿ç”¨åœºæ™¯ï¼‰
        2. ä» related_functions ä¸­æå–ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        3. ä½¿ç”¨å¯å‘å¼è§„åˆ™ï¼ˆä»…åœ¨å®Œå…¨æ²¡æœ‰usage examplesæ—¶ä½¿ç”¨ï¼Œä½œä¸ºæœ€åæ‰‹æ®µï¼‰
        
        æ³¨æ„ï¼šä¼˜å…ˆä½¿ç”¨çœŸå®ä»£ç ä¸­çš„ä½¿ç”¨æ¨¡å¼ï¼Œè€Œä¸æ˜¯åŸºäºå‡½æ•°åæ¨¡å¼çš„çŒœæµ‹
        """
        prerequisites = []
        
        # ç­–ç•¥ 1: ä» usage examples ä¸­æå–çœŸå®çš„APIç»„åˆæ¨¡å¼ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        usage_based_prereqs = self._extract_prerequisites_from_usage_examples(func, context)
        if usage_based_prereqs:
            prerequisites.extend(usage_based_prereqs)
            logger.info(f"âœ“ Found {len(usage_based_prereqs)} prerequisite APIs from real-world usage examples")
        
        # ç­–ç•¥ 2: ä» related_functions ä¸­æå–ï¼ˆä½œä¸ºè¡¥å……ä¿¡æ¯ï¼‰
        # æ³¨æ„ï¼šåªæ·»åŠ ä¸åœ¨prerequisitesä¸­çš„å‡½æ•°ï¼Œé¿å…é‡å¤
        for related in context.get('related_functions', []):
            if related['type'] == 'initialization':
                func_name = related['name']
                if func_name not in prerequisites:
                    prerequisites.append(func_name)
                    logger.debug(f"Added prerequisite from related_functions: {func_name}")
        
        # ç­–ç•¥ 3: å¯å‘å¼è§„åˆ™ï¼ˆä»…åœ¨å®Œå…¨æ²¡æœ‰usage examplesæ—¶ä½¿ç”¨ï¼Œä½œä¸ºæœ€åæ‰‹æ®µï¼‰
        # è¿™æ˜¯ä¸€ä¸ªfallbackï¼Œä¸åº”è¯¥ä½œä¸ºä¸»è¦æ–¹æ³•
        if not prerequisites and not context.get('usage_examples'):
            logger.warning("No usage examples available, falling back to heuristics (less reliable)")
            heuristic_prereqs = self._find_prerequisites_heuristic(func, context)
            prerequisites.extend(heuristic_prereqs)
            if heuristic_prereqs:
                logger.debug(f"Found {len(heuristic_prereqs)} prerequisites using heuristics (fallback only)")
        elif not prerequisites:
            logger.warning(f"Usage examples exist but no prerequisites extracted - this may indicate the function has no dependencies")
        
        return prerequisites
    
    def _extract_prerequisites_from_usage_examples(
        self,
        target_func: str,
        context: Dict
    ) -> List[str]:
        """
        ä» usage examples ä¸­æå–å‰ç½®ä¾èµ–ï¼ˆAPIç»„åˆæ¨¡å¼ï¼‰
        
        æ”¹è¿›ç­–ç•¥ï¼š
        1. æå–æ‰€æœ‰å‡½æ•°è°ƒç”¨ï¼ˆä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°ï¼‰
        2. æ‰¾åˆ°ç›®æ ‡å‡½æ•°çš„ä½ç½®
        3. æå–åœ¨ç›®æ ‡å‡½æ•°ä¹‹å‰è°ƒç”¨çš„æ‰€æœ‰APIï¼ˆçœŸå®ä½¿ç”¨åœºæ™¯ä¸­çš„ç»„åˆï¼‰
        4. ç»Ÿè®¡é¢‘ç‡ï¼Œæ‰¾å‡ºæœ€å¸¸è§çš„APIç»„åˆæ¨¡å¼
        5. ä¿ç•™è°ƒç”¨é¡ºåºï¼Œè¿”å›æŒ‰é¢‘ç‡æ’åºçš„APIåˆ—è¡¨
        
        ä¸å†ä¾èµ–å¯å‘å¼è§„åˆ™åˆ¤æ–­"åˆå§‹åŒ–å‡½æ•°"ï¼Œè€Œæ˜¯åŸºäºçœŸå®ä»£ç ä¸­çš„ä½¿ç”¨æ¨¡å¼
        """
        usage_examples = context.get('usage_examples', [])
        if not usage_examples:
            return []
        
        # æå–ç®€å•å‡½æ•°åï¼ˆç”¨äºåŒ¹é…ï¼‰
        target_func_simple = self._extract_function_name(target_func)
        if not target_func_simple:
            target_func_simple = target_func.split('(')[0].strip()
        
        # æ”¶é›†æ‰€æœ‰ç¤ºä¾‹ä¸­çš„è°ƒç”¨åºåˆ—
        all_call_sequences = []
        
        for example in usage_examples:
            source_code = example.get('source', '')
            if not source_code:
                continue
            
            # æå–å‡½æ•°è°ƒç”¨åºåˆ—
            calls = self._extract_function_calls_from_code(source_code)
            if not calls:
                continue
            
            # æ‰¾åˆ°ç›®æ ‡å‡½æ•°çš„ä½ç½®
            target_pos = self._find_function_in_calls(calls, target_func_simple)
            if target_pos is None:
                # å¦‚æœæ‰¾ä¸åˆ°ç›®æ ‡å‡½æ•°ï¼Œè·³è¿‡è¿™ä¸ªç¤ºä¾‹
                continue
            
            # æå–ç›®æ ‡å‡½æ•°ä¹‹å‰çš„æ‰€æœ‰APIè°ƒç”¨ï¼ˆä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°ï¼‰
            prereqs = []
            for i in range(target_pos):
                func_name = self._normalize_function_name(calls[i])
                # åªä¿ç•™é¡¹ç›®ä¸­çœŸå®å­˜åœ¨çš„APIå‡½æ•°ï¼ˆé¿å…è¯¯åŒ¹é…ï¼‰
                if self._function_exists(func_name):
                    prereqs.append(func_name)
            
            if prereqs:
                all_call_sequences.append(prereqs)
                logger.debug(f"Found {len(prereqs)} API calls before {target_func_simple} in example")
        
        if not all_call_sequences:
            return []
        
        # ç»Ÿè®¡æ‰€æœ‰APIå‡½æ•°çš„å‡ºç°é¢‘ç‡ï¼ˆä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°ï¼‰
        api_func_counts = {}
        for sequence in all_call_sequences:
            for func_name in sequence:
                api_func_counts[func_name] = api_func_counts.get(func_name, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åºï¼Œè¿”å›æœ€å¸¸è§çš„APIç»„åˆ
        sorted_apis = sorted(
            api_func_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # è¿”å›é¢‘ç‡ >= 1 çš„å‡½æ•°ï¼ˆè‡³å°‘åœ¨ä¸€ä¸ªç¤ºä¾‹ä¸­å‡ºç°ï¼‰
        # è¿™äº›æ˜¯çœŸå®ä½¿ç”¨åœºæ™¯ä¸­ä¸ç›®æ ‡å‡½æ•°ç»„åˆä½¿ç”¨çš„API
        result = [func for func, count in sorted_apis if count >= 1]
        
        if result:
            logger.info(f"âœ“ Extracted {len(result)} prerequisite APIs from usage examples (real-world patterns): {result}")
        
        return result
    
    def _extract_function_calls_from_code(self, code: str) -> List[str]:
        """
        ä»ä»£ç ä¸­æå–å‡½æ•°è°ƒç”¨
        
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¸¸è§çš„å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼š
        - func_name(...)
        - func_name ( ... )
        - obj->method(...)
        - obj.method(...)
        """
        import re
        
        # åŒ¹é…å‡½æ•°è°ƒç”¨ï¼šidentifier(...) æˆ– identifier ( ... )
        # æ’é™¤å…³é”®å­—ã€ç±»å‹åç­‰
        pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*(?:_[a-zA-Z0-9_]+)*)\s*\([^)]*\)'
        
        matches = re.findall(pattern, code)
        
        # è¿‡æ»¤æ‰å¸¸è§çš„å…³é”®å­—å’Œç±»å‹
        excluded = {
            'if', 'while', 'for', 'switch', 'return', 'sizeof',
            'malloc', 'free', 'calloc', 'realloc',  # è¿™äº›æ˜¯é€šç”¨çš„ï¼Œä¸æ˜¯ API ç‰¹å®šçš„
        }
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„åç§°ï¼ˆå¯èƒ½æ˜¯å˜é‡ï¼‰
        filtered = [
            m for m in matches
            if m not in excluded and len(m) > 2
        ]
        
        return filtered
    
    def _find_function_in_calls(self, calls: List[str], target_func: str) -> Optional[int]:
        """
        åœ¨è°ƒç”¨åˆ—è¡¨ä¸­æŸ¥æ‰¾ç›®æ ‡å‡½æ•°çš„ä½ç½®
        
        æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¤„ç†å‡½æ•°åå˜ä½“ï¼‰
        """
        target_lower = target_func.lower()
        
        for i, call in enumerate(calls):
            call_lower = call.lower()
            # ç²¾ç¡®åŒ¹é…
            if call_lower == target_lower:
                return i
            # éƒ¨åˆ†åŒ¹é…ï¼ˆå¤„ç†å‘½åç©ºé—´å‰ç¼€ï¼‰
            if call_lower.endswith('_' + target_lower) or target_lower in call_lower:
                return i
        
        return None
    
    def _normalize_function_name(self, func_call: str) -> str:
        """
        è§„èŒƒåŒ–å‡½æ•°åï¼ˆç§»é™¤å¯èƒ½çš„å‚æ•°ä¿¡æ¯ï¼‰
        """
        # ç§»é™¤å¯èƒ½çš„å‚æ•°éƒ¨åˆ†
        if '(' in func_call:
            return func_call.split('(')[0].strip()
        return func_call.strip()
    
    def _is_initialization_function(self, func_name: str) -> bool:
        """
        åˆ¤æ–­å‡½æ•°æ˜¯å¦æ˜¯åˆå§‹åŒ–å‡½æ•°ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰
        
        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ç°åœ¨ä¸»è¦ç”¨äºå‘åå…¼å®¹ã€‚æ–°çš„å®ç°åº”è¯¥åŸºäº
        usage examplesä¸­çš„çœŸå®ä½¿ç”¨æ¨¡å¼ï¼Œè€Œä¸æ˜¯å‡½æ•°åæ¨¡å¼åŒ¹é…ã€‚
        """
        func_lower = func_name.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆå§‹åŒ–åç¼€
        has_init_suffix = any(
            func_lower.endswith(suffix) or suffix in func_lower
            for suffix in INIT_SUFFIXES
        )
        
        if not has_init_suffix:
            return False
        
        # éªŒè¯å‡½æ•°ç¡®å®å­˜åœ¨ï¼ˆé¿å…è¯¯åŒ¹é…ï¼‰
        return self._function_exists(func_name)
    
    def _find_prerequisites_heuristic(
        self,
        func: str,
        context: Dict
    ) -> List[str]:
        """
        ä½¿ç”¨å¯å‘å¼è§„åˆ™æŸ¥æ‰¾å‰ç½®ä¾èµ–ï¼ˆfallback æ–¹æ³•ï¼‰
        """
        prerequisites = []
        
        # ä» initialization_patterns ä¸­æå–
        for pattern in context.get('initialization_patterns', []):
            param_type = pattern['type']
            base_name = get_base_name_from_type(param_type)
            
            # ç­–ç•¥ 1: ç›´æ¥åŒ¹é… base_name + suffix
            found = False
            for suffix in INIT_SUFFIXES:
                init_func = base_name + suffix
                if self._function_exists(init_func):
                    prerequisites.append(init_func)
                    logger.debug(f"Found prerequisite (heuristic): {init_func} for type {param_type}")
                    found = True
                    break
            
            # ç­–ç•¥ 2: æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼‰
            if not found:
                fuzzy_matches = self._fuzzy_match_init_function(base_name)
                if fuzzy_matches:
                    prerequisites.extend(fuzzy_matches[:1])  # åªå–ç¬¬ä¸€ä¸ªåŒ¹é…
                    logger.debug(f"Found prerequisite (fuzzy): {fuzzy_matches[0]} for type {param_type}")
        
        return prerequisites
    
    def _fuzzy_match_init_function(self, base_name: str) -> List[str]:
        """
        æ¨¡ç³ŠåŒ¹é…åˆå§‹åŒ–å‡½æ•°
        
        æŸ¥æ‰¾æ‰€æœ‰åŒ…å« base_name å’Œåˆå§‹åŒ–åç¼€çš„å‡½æ•°
        ä¾‹å¦‚ï¼šbase_name="curl" -> åŒ¹é… "curl_easy_init", "curl_global_init" ç­‰
        """
        self._ensure_function_cache()
        if not self._all_functions_cache:
            return []
        
        base_lower = base_name.lower()
        matches = []
        
        for func_name in self._all_functions_cache:
            func_lower = func_name.lower()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å« base_name å’Œåˆå§‹åŒ–åç¼€
            if base_lower in func_lower:
                for suffix in INIT_SUFFIXES:
                    if func_lower.endswith(suffix):
                        matches.append(func_name)
                        break
        
        return matches
    
    def _extract_function_name(self, func_sig: str) -> Optional[str]:
        """
        ä»å‡½æ•°ç­¾åä¸­æå–ç®€å•å‡½æ•°å
        
        ä¾‹å¦‚: "void curl_easy_setopt(CURL *, ...)" -> "curl_easy_setopt"
        """
        import re
        match = re.search(r'\b([a-zA-Z_][a-zA-Z0-9_]*(?:_[a-zA-Z0-9_]+)*)\s*\(', func_sig)
        if match:
            return match.group(1)
        return None
    
    def _extract_call_sequence_from_usage_examples(
        self,
        target_func: str,
        context: Dict
    ) -> Optional[List[str]]:
        """
        ä» usage examples ä¸­æå–å®Œæ•´çš„APIç»„åˆè°ƒç”¨åºåˆ—
        
        æ”¹è¿›ç­–ç•¥ï¼š
        1. åˆ†ææ¯ä¸ªç¤ºä¾‹ä¸­çš„å®Œæ•´å‡½æ•°è°ƒç”¨é¡ºåºï¼ˆåŒ…æ‹¬é…ç½®ã€ä½¿ç”¨ã€æ¸…ç†ç­‰ï¼‰
        2. è¯†åˆ«ä¸ç›®æ ‡å‡½æ•°ä¸€èµ·ä½¿ç”¨çš„æ‰€æœ‰APIï¼ˆä¸ä»…ä»…æ˜¯åˆå§‹åŒ–å‡½æ•°ï¼‰
        3. æ‰¾åˆ°æœ€å¸¸è§çš„APIç»„åˆæ¨¡å¼
        4. è¿”å›åŒ…å«ç›®æ ‡å‡½æ•°åŠå…¶å®Œæ•´ä¾èµ–çš„åºåˆ—
        
        ä¸å†åªå…³æ³¨"åˆå§‹åŒ–"å’Œ"æ¸…ç†"ï¼Œè€Œæ˜¯æå–çœŸå®ä½¿ç”¨åœºæ™¯ä¸­çš„å®Œæ•´APIç»„åˆ
        """
        usage_examples = context.get('usage_examples', [])
        if not usage_examples:
            return None
        
        target_func_simple = self._extract_function_name(target_func)
        if not target_func_simple:
            target_func_simple = target_func.split('(')[0].strip()
        
        # æ”¶é›†æ‰€æœ‰ç¤ºä¾‹ä¸­çš„å®Œæ•´è°ƒç”¨åºåˆ—
        all_sequences = []
        
        for example in usage_examples:
            source_code = example.get('source', '')
            if not source_code:
                continue
            
            # æå–å‡½æ•°è°ƒç”¨åºåˆ—
            calls = self._extract_function_calls_from_code(source_code)
            if not calls:
                continue
            
            # æ‰¾åˆ°ç›®æ ‡å‡½æ•°çš„ä½ç½®
            target_pos = self._find_function_in_calls(calls, target_func_simple)
            if target_pos is None:
                continue
            
            # æå–åŒ…å«ç›®æ ‡å‡½æ•°çš„å®Œæ•´APIåºåˆ—
            # åŒ…æ‹¬ï¼šç›®æ ‡å‡½æ•°ä¹‹å‰çš„æ‰€æœ‰API + ç›®æ ‡å‡½æ•° + ç›®æ ‡å‡½æ•°ä¹‹åçš„ç›¸å…³API
            sequence = []
            
            # ç›®æ ‡å‡½æ•°ä¹‹å‰çš„æ‰€æœ‰APIè°ƒç”¨ï¼ˆçœŸå®ä½¿ç”¨åœºæ™¯ä¸­çš„ç»„åˆï¼‰
            for i in range(target_pos):
                func_name = self._normalize_function_name(calls[i])
                # åªä¿ç•™é¡¹ç›®ä¸­çœŸå®å­˜åœ¨çš„APIå‡½æ•°
                if self._function_exists(func_name):
                    sequence.append(func_name)
            
            # ç›®æ ‡å‡½æ•°æœ¬èº«
            sequence.append(target_func_simple)
            
            # ç›®æ ‡å‡½æ•°ä¹‹åçš„APIè°ƒç”¨ï¼ˆåŒ…æ‹¬æ¸…ç†ã€ç»“æœæŸ¥è¯¢ç­‰ï¼‰
            # ä¸å†åªæ£€æŸ¥"æ¸…ç†å‡½æ•°"ï¼Œè€Œæ˜¯æå–æ‰€æœ‰ç›¸å…³çš„APIè°ƒç”¨
            for i in range(target_pos + 1, len(calls)):
                func_name = self._normalize_function_name(calls[i])
                if self._function_exists(func_name):
                    # æ£€æŸ¥æ˜¯å¦ä¸ç›®æ ‡å‡½æ•°ç›¸å…³ï¼ˆæœ‰å…±åŒå‰ç¼€æˆ–å‘½åç©ºé—´ï¼‰
                    # æˆ–è€…æ˜¯åœ¨çœŸå®ä»£ç ä¸­ä¸€èµ·ä½¿ç”¨çš„å‡½æ•°
                    if (self._is_related_function(func_name, target_func_simple) or
                        self._is_cleanup_function(func_name) or
                        self._appears_together_in_examples(func_name, target_func_simple, usage_examples)):
                        sequence.append(func_name)
            
            if len(sequence) > 1:  # è‡³å°‘åŒ…å«ç›®æ ‡å‡½æ•°å’Œä¸€ä¸ªä¾èµ–
                all_sequences.append(sequence)
                logger.debug(f"Extracted complete API sequence from example: {sequence}")
        
        if not all_sequences:
            return None
        
        # æ‰¾åˆ°æœ€å¸¸è§çš„APIç»„åˆæ¨¡å¼
        # ç­–ç•¥ï¼šç»Ÿè®¡æ¯ä¸ªå‡½æ•°åœ¨åºåˆ—ä¸­å‡ºç°çš„é¢‘ç‡å’Œå¹³å‡ä½ç½®
        func_positions = {}  # {func_name: [positions]}
        func_frequencies = {}  # {func_name: count}
        
        for sequence in all_sequences:
            for pos, func in enumerate(sequence):
                if func not in func_positions:
                    func_positions[func] = []
                    func_frequencies[func] = 0
                func_positions[func].append(pos)
                func_frequencies[func] += 1
        
        # è®¡ç®—æ¯ä¸ªå‡½æ•°çš„å¹³å‡ä½ç½®ï¼ˆè€ƒè™‘é¢‘ç‡æƒé‡ï¼‰
        func_avg_pos = {}
        for func, positions in func_positions.items():
            # å¹³å‡ä½ç½®ï¼Œä½†ä¼˜å…ˆè€ƒè™‘å‡ºç°é¢‘ç‡é«˜çš„å‡½æ•°
            avg_pos = sum(positions) / len(positions)
            # ç»“åˆé¢‘ç‡å’Œä½ç½®ï¼šé¢‘ç‡é«˜çš„å‡½æ•°å³ä½¿ä½ç½®ç¨åï¼Œä¹Ÿåº”è¯¥ä¼˜å…ˆ
            func_avg_pos[func] = (avg_pos, func_frequencies[func])
        
        # æŒ‰å¹³å‡ä½ç½®æ’åºï¼ˆä¸»è¦ï¼‰ï¼Œé¢‘ç‡ä½œä¸ºæ¬¡è¦æ’åº
        sorted_funcs = sorted(
            func_avg_pos.items(),
            key=lambda x: (x[1][0], -x[1][1])  # ä½ç½®ä¼˜å…ˆï¼Œé¢‘ç‡æ¬¡ä¹‹ï¼ˆè´Ÿå·è¡¨ç¤ºé™åºï¼‰
        )
        result = [func for func, _ in sorted_funcs]
        
        # ç¡®ä¿ç›®æ ‡å‡½æ•°åœ¨åºåˆ—ä¸­
        if target_func_simple not in result:
            result.append(target_func_simple)
        
        if len(result) > 1:
            logger.info(f"âœ“ Extracted complete API combination sequence ({len(result)} APIs): {result}")
        
        return result if len(result) > 1 else None
    
    def _appears_together_in_examples(
        self,
        func1: str,
        func2: str,
        usage_examples: List[Dict]
    ) -> bool:
        """
        æ£€æŸ¥ä¸¤ä¸ªå‡½æ•°æ˜¯å¦åœ¨usage examplesä¸­ç»å¸¸ä¸€èµ·å‡ºç°
        
        è¿™ç”¨äºè¯†åˆ«çœŸå®ä½¿ç”¨åœºæ™¯ä¸­çš„APIç»„åˆæ¨¡å¼
        """
        together_count = 0
        total_count = 0
        
        for example in usage_examples:
            source_code = example.get('source', '')
            if not source_code:
                continue
            
            calls = self._extract_function_calls_from_code(source_code)
            if not calls:
                continue
            
            normalized_calls = [self._normalize_function_name(c) for c in calls]
            
            has_func1 = func1 in normalized_calls
            has_func2 = func2 in normalized_calls
            
            if has_func1 or has_func2:
                total_count += 1
                if has_func1 and has_func2:
                    together_count += 1
        
        # å¦‚æœä¸¤ä¸ªå‡½æ•°åœ¨è‡³å°‘50%çš„ç¤ºä¾‹ä¸­ä¸€èµ·å‡ºç°ï¼Œè®¤ä¸ºå®ƒä»¬æ˜¯ç»„åˆä½¿ç”¨çš„
        return total_count > 0 and (together_count / total_count) >= 0.5
    
    def _is_cleanup_function(self, func_name: str) -> bool:
        """åˆ¤æ–­å‡½æ•°æ˜¯å¦æ˜¯æ¸…ç†å‡½æ•°"""
        func_lower = func_name.lower()
        return any(
            func_lower.endswith(suffix) or suffix in func_lower
            for suffix in CLEANUP_SUFFIXES
        ) and self._function_exists(func_name)
    
    def _is_related_function(self, func_name: str, target_func: str) -> bool:
        """
        åˆ¤æ–­å‡½æ•°æ˜¯å¦ä¸ç›®æ ‡å‡½æ•°ç›¸å…³
        
        æ£€æŸ¥ï¼š
        1. å‡½æ•°åæœ‰å…±åŒçš„å‰ç¼€
        2. å‡½æ•°å­˜åœ¨äºé¡¹ç›®ä¸­
        """
        if not self._function_exists(func_name):
            return False
        
        # æå–å…±åŒå‰ç¼€ï¼ˆä¾‹å¦‚ï¼šcurl_easy_setopt å’Œ curl_easy_perform éƒ½æœ‰ curl_easy_ å‰ç¼€ï¼‰
        target_parts = target_func.lower().split('_')
        func_parts = func_name.lower().split('_')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘ 2 ä¸ªå…±åŒçš„å‰ç¼€éƒ¨åˆ†
        common_prefix_len = 0
        for i in range(min(len(target_parts), len(func_parts))):
            if target_parts[i] == func_parts[i]:
                common_prefix_len += 1
            else:
                break
        
        # å¦‚æœæœ‰è‡³å°‘ 2 ä¸ªå…±åŒå‰ç¼€ï¼Œè®¤ä¸ºæ˜¯ç›¸å…³å‡½æ•°
        return common_prefix_len >= 2
    
    def _analyze_data_dependencies(
        self, 
        func: str, 
        context: Dict
    ) -> List[Tuple[str, str]]:
        """
        åˆ†æå“ªäº›å‚æ•°å¿…é¡»æ¥è‡ªå…¶ä»–å‡½æ•°çš„è¿”å›å€¼
        
        ç­–ç•¥ï¼š
        1. å¯¹äºå¤æ‚ç±»å‹ï¼ˆéåŸºæœ¬ç±»å‹ï¼‰ï¼ŒæŸ¥æ‰¾ç”Ÿäº§è€…å‡½æ•°
        2. ä½¿ç”¨ FuzzIntrospector çš„ç±»å‹ä¿¡æ¯
        """
        deps = []
        
        for param in context.get('parameters', []):
            param_type = clean_type_name(param['type'])
            param_name = param['name']
            
            # è·³è¿‡åŸºæœ¬ç±»å‹
            if is_primitive_type(param_type):
                continue
            
            # æŸ¥æ‰¾ç”Ÿäº§è€…å‡½æ•°ï¼ˆè¿”å›è¯¥ç±»å‹çš„å‡½æ•°ï¼‰
            producer = self._find_producer_function(param_type)
            if producer:
                deps.append((producer, func))
                logger.debug(f"Found data dependency: {producer} -> {func} (type: {param_type})")
        
        return deps
    
    def _find_producer_function(self, type_name: str) -> Optional[str]:
        """
        æŸ¥æ‰¾è¿”å›ç»™å®šç±»å‹çš„å‡½æ•°ï¼ˆé€šå¸¸æ˜¯æ„é€ å™¨ï¼‰
        
        å¯å‘å¼è§„åˆ™ï¼š
        1. base_name_create/new/alloc
        2. æŸ¥è¯¢ FuzzIntrospector è·å–è¿”å›è¯¥ç±»å‹çš„å‡½æ•°
        """
        base = get_base_name_from_type(type_name)
        
        # è§„åˆ™ 1: å¸¸è§çš„æ„é€ å™¨å‘½åæ¨¡å¼
        for suffix in INIT_SUFFIXES:
            candidate = base + suffix
            if self._function_exists(candidate):
                return candidate
        
        # è§„åˆ™ 2: ä½¿ç”¨ FuzzIntrospector æŸ¥è¯¢ï¼ˆå¦‚æœ API æ”¯æŒï¼‰
        # TODO: FuzzIntrospector æœ‰ query_introspector_matching_function_constructor_type
        # ä½†è¿™æ˜¯ä¸º Java è®¾è®¡çš„ï¼Œéœ€è¦æ£€æŸ¥ C/C++ æ”¯æŒ
        
        return None
    
    def _generate_call_sequence(self) -> List[str]:
        """
        æ‹“æ‰‘æ’åºç”Ÿæˆæ­£ç¡®çš„è°ƒç”¨é¡ºåº
        """
        try:
            if HAS_NETWORKX:
                return list(nx.topological_sort(self.graph))
            else:
                return self.graph.topological_sort_dfs()
        except Exception as e:
            logger.warning(f"Topological sort failed: {e}, using simple order")
            # å¦‚æœæœ‰ç¯æˆ–å…¶ä»–é—®é¢˜ï¼Œè¿”å›ç®€å•é¡ºåº
            if HAS_NETWORKX:
                return list(self.graph.nodes())
            else:
                return self.graph.get_nodes()
    
    def _generate_initialization_code(
        self, 
        target_func: str,
        context: Dict, 
        prerequisites: List[str]
    ) -> List[str]:
        """
        ç”Ÿæˆåˆå§‹åŒ–ä»£ç æ¨¡æ¿
        
        Returns:
            ä»£ç ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€è¡Œåˆå§‹åŒ–ä»£ç 
        """
        code_lines = []
        
        if not prerequisites and not context.get('initialization_patterns'):
            return code_lines
        
        code_lines.append("// Initialize required data structures")
        
        # ä¸ºæ¯ä¸ªåˆå§‹åŒ–æ¨¡å¼ç”Ÿæˆä»£ç 
        for pattern in context.get('initialization_patterns', []):
            param_type = pattern['type']
            param_name = pattern['parameter']
            method = pattern.get('method', '')
            
            # ç”Ÿæˆå˜é‡å£°æ˜
            code_lines.append(f"{param_type} {param_name};")
            
            # ç”Ÿæˆåˆå§‹åŒ–è°ƒç”¨
            if method:
                # æ›¿æ¢å ä½ç¬¦
                init_code = method.replace('&var', f'&{param_name}')
                init_code = init_code.replace('var', param_name)
                code_lines.append(init_code + ";")
            else:
                # é»˜è®¤ï¼šä½¿ç”¨ memset
                code_lines.append(f"memset(&{param_name}, 0, sizeof({param_type}));")
        
        # ä¸º prerequisites ç”Ÿæˆè°ƒç”¨
        for prereq in prerequisites:
            code_lines.append(f"// Call prerequisite: {prereq}")
            code_lines.append(f"{prereq}(...);  // TODO: Fill in parameters")
        
        return code_lines
    
    def _ensure_function_cache(self):
        """Lazy load function cache once"""
        if self._all_functions_cache is not None:
            return
        
        try:
            all_funcs = introspector.query_introspector_all_functions(self.project_name)
            # Collect all possible name variations
            names = set()
            for f in all_funcs:
                for key in ['function_signature', 'function-name', 'raw_function_name']:
                    if name := f.get(key):
                        names.add(name)
                        # Also add simple name extracted from signature
                        if '(' in name:
                            simple = re.search(r'\b([a-zA-Z_]\w*)\s*\(', name)
                            if simple:
                                names.add(simple.group(1))
            
            self._all_functions_cache = names
            logger.debug(f"Cached {len(names)} function names")
        except Exception as e:
            logger.debug(f"Could not load function cache: {e}")
            self._all_functions_cache = set()
    
    def _function_exists(self, func_name: str) -> bool:
        """Check if function exists (cached)"""
        self._ensure_function_cache()
        return func_name in self._all_functions_cache


def format_api_combinations_for_prompt(api_combinations: Dict, target_function: str) -> str:
    """
    å°†APIç»„åˆä¿¡æ¯æ ¼å¼åŒ–ä¸ºé€‚åˆæ³¨å…¥ prompt çš„æ–‡æœ¬
    
    Args:
        api_combinations: find_api_combinations() è¿”å›çš„å­—å…¸
        target_function: ç›®æ ‡å‡½æ•°å
    
    Returns:
        æ ¼å¼åŒ–çš„ Markdown æ–‡æœ¬
    """
    if not api_combinations:
        return ""
    
    sections = []
    sections.append("## ğŸ”— API Composition Analysis\n")
    
    # Check if this is LLM-enhanced analysis
    llm_metadata = api_combinations.get('llm_metadata', {})
    is_llm_enhanced = bool(llm_metadata)
    
    if is_llm_enhanced:
        sections.append("**Source**: LLM-enhanced analysis (high confidence)\n")
        if llm_metadata.get('confidence_note'):
            sections.append(f"**Note**: {llm_metadata['confidence_note']}\n")
    
    # 1. è°ƒç”¨é¡ºåº
    if api_combinations.get('call_sequence'):
        sections.append("### âœ… Recommended Call Sequence\n")
        sections.append("**IMPORTANT**: Follow this order to ensure correct API usage:\n")
        for i, func in enumerate(api_combinations['call_sequence'], 1):
            if func == target_function:
                sections.append(f"{i}. **`{func}`** â† TARGET FUNCTION")
            else:
                sections.append(f"{i}. `{func}`")
        sections.append("")
    
    # 2. å‰ç½®ä¾èµ–ï¼ˆåˆå§‹åŒ–ï¼‰
    if api_combinations.get('prerequisites'):
        sections.append("### âš ï¸ Prerequisites (Initialization)\n")
        sections.append("These functions **MUST** be called before the target function:\n")
        for prereq in api_combinations['prerequisites']:
            sections.append(f"- `{prereq}()` - Initialize required resources")
        sections.append("")
    
    # 3. LLM-enhanced: Configuration functions
    if is_llm_enhanced and llm_metadata.get('configuration_functions'):
        sections.append("### âš™ï¸ Configuration Functions\n")
        sections.append("Use these to configure objects before calling the target:\n")
        for config_func in llm_metadata['configuration_functions']:
            sections.append(f"- `{config_func}()` - Set options/parameters")
        sections.append("")
    
    # 4. LLM-enhanced: Complementary functions
    if is_llm_enhanced and llm_metadata.get('complementary_functions'):
        sections.append("### ğŸ“¤ Complementary Functions (Post-processing)\n")
        sections.append("Consider calling these after the target to query results:\n")
        for comp_func in llm_metadata['complementary_functions']:
            sections.append(f"- `{comp_func}()` - Get status/results")
        sections.append("")
    
    # 5. LLM-enhanced: Cleanup functions
    if is_llm_enhanced and llm_metadata.get('cleanup_functions'):
        sections.append("### ğŸ§¹ Cleanup Functions\n")
        sections.append("Call these to free resources (in reverse order):\n")
        for cleanup_func in llm_metadata['cleanup_functions']:
            sections.append(f"- `{cleanup_func}()` - Free resources")
        sections.append("")
    
    # 6. æ•°æ®ä¾èµ–
    if api_combinations.get('data_dependencies'):
        sections.append("### ğŸ“Š Data Flow Dependencies\n")
        for src, dst in api_combinations['data_dependencies']:
            sections.append(f"- `{src}` produces data consumed by `{dst}`")
        sections.append("")
    
    # 7. åˆå§‹åŒ–ä»£ç æ¨¡æ¿
    if api_combinations.get('initialization_code'):
        sections.append("### ğŸ’¡ Initialization Code Template\n")
        sections.append("```c")
        sections.extend(api_combinations['initialization_code'])
        sections.append("```\n")
    
    # 8. LLM call pattern example (if available)
    if is_llm_enhanced and llm_metadata.get('has_call_pattern'):
        sections.append("### ğŸ“ Complete Usage Pattern\n")
        sections.append("```c")
        # Extract from initialization_code (which contains the call pattern)
        for line in api_combinations.get('initialization_code', []):
            if line.startswith('//'):
                sections.append(line.replace('// ', ''))
        sections.append("```\n")
    
    return "\n".join(sections)


def get_api_combinations(project_name: str, target_function: str) -> Optional[Dict]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–å¯ä»¥ä¸ç›®æ ‡å‡½æ•°ç»„åˆä½¿ç”¨çš„API
    
    Args:
        project_name: é¡¹ç›®åç§°ï¼ˆå¦‚ "igraph"ï¼‰
        target_function: ç›®æ ‡å‡½æ•°ç­¾å
    
    Returns:
        APIç»„åˆä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæŸ¥æ‰¾å¤±è´¥åˆ™è¿”å› None
    """
    try:
        analyzer = APICompositionAnalyzer(project_name)
        api_combinations = analyzer.find_api_combinations(target_function)
        return api_combinations if api_combinations['call_sequence'] else None
    except Exception as e:
        logger.error(f"Failed to get API combinations: {e}", exc_info=True)
        return None


if __name__ == "__main__":
    # æµ‹è¯•
    import sys
    logging.basicConfig(level=logging.DEBUG)
    
    if len(sys.argv) < 3:
        print("Usage: python api_composition_analyzer.py <project_name> <function_name>")
        sys.exit(1)
    
    project = sys.argv[1]
    func = sys.argv[2]
    
    # è®¾ç½® FuzzIntrospector endpoint
    from data_prep.introspector import set_introspector_endpoints, DEFAULT_INTROSPECTOR_ENDPOINT
    set_introspector_endpoints(DEFAULT_INTROSPECTOR_ENDPOINT)
    
    analyzer = APICompositionAnalyzer(project)
    result = analyzer.find_api_combinations(func)
    
    print("\n" + "="*60)
    print(format_api_combinations_for_prompt(result, func))
    print("="*60)

