# å¦‚ä½•è¿è¡Œ LangGraph Workflow

æµ‹è¯• cJSON é¡¹ç›®çš„å¿«é€ŸæŒ‡å—

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ LangGraph ä¸»å…¥å£ï¼ˆæ¨èï¼‰

```bash
# åŸºæœ¬è¿è¡Œ - å¤„ç† cJSON_Parse å‡½æ•°
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat
```

### æ–¹æ³• 2: ä½¿ç”¨ä¼ ç»Ÿ run_single_fuzz.py + agent æ¨¡å¼

```bash
# éœ€è¦å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœä½¿ç”¨æœ¬åœ° AIï¼‰
export AI_BINARY=/path/to/ai/binary  # å¯é€‰

# è¿è¡Œ LangGraph workflow
python3 run_single_fuzz.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  --agent
```

---

## ğŸ“‹ å‘½ä»¤å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `-y, --benchmark-yaml` | Benchmark YAML æ–‡ä»¶è·¯å¾„ | `-y conti-benchmark/cjson.yaml` |
| `-f, --function-name` | è¦æµ‹è¯•çš„å‡½æ•°å | `-f cJSON_Parse` |
| `--model` | LLM æ¨¡å‹åç§° | `--model vertex_ai_gemini-2-5-pro-chat` |

### å¯é€‰å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--workflow-type` | Workflow ç±»å‹ | `full` |
| `--trial` | Trial ç¼–å· | `0` |
| `--max-iterations` | æœ€å¤§è¿­ä»£æ¬¡æ•° | `5` |
| `--run-timeout` | è¿è¡Œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ | `60` |
| `--context` | æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ | `false` |
| `-v, --verbose` | è¯¦ç»†æ—¥å¿— | `false` |

---

## ğŸ¯ å®Œæ•´ç¤ºä¾‹å‘½ä»¤

### 1. æµ‹è¯• cJSON_Parseï¼ˆåŸºç¡€ï¼‰

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat
```

### 2. æµ‹è¯• cJSON_ParseWithLengthï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_ParseWithLength \
  --model vertex_ai_gemini-2-5-pro-chat \
  --context
```

### 3. è¯¦ç»†æ—¥å¿— + è‡ªå®šä¹‰è¿­ä»£æ¬¡æ•°

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  --max-iterations 10 \
  --run-timeout 120 \
  --verbose
```

### 4. å¤„ç† YAML ä¸­çš„æ‰€æœ‰å‡½æ•°

```bash
# ä¸æŒ‡å®š -f å‚æ•°ï¼Œä¼šå¤„ç†æ‰€æœ‰å‡½æ•°
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  --model vertex_ai_gemini-2-5-pro-chat
```

---

## ğŸ”§ å¯ç”¨çš„ LLM æ¨¡å‹

æ ¹æ® `llm_toolkit/models.py`ï¼Œå¯ç”¨çš„æ¨¡å‹åŒ…æ‹¬ï¼š

### Vertex AI (Google Cloud)
```bash
--model vertex_ai_gemini-2-5-pro-chat
--model vertex_ai_gemini-1.5-flash
--model vertex_ai_gemini-1.5-pro
```

### OpenAI
```bash
--model gpt-4o
--model gpt-4-turbo
--model gpt-3.5-turbo
```

### Claude
```bash
--model claude-3-5-sonnet
--model claude-3-opus
```

---

## ğŸ“‚ è¾“å‡ºç›®å½•ç»“æ„

è¿è¡Œåä¼šåœ¨ `results/` ç›®å½•ä¸‹åˆ›å»ºè¾“å‡ºï¼š

```
results/
â””â”€â”€ output-cjson-cJSON_Parse/
    â”œâ”€â”€ benchmark.yaml              # ä½¿ç”¨çš„ benchmark é…ç½®
    â”œâ”€â”€ status/                     # è¿è¡ŒçŠ¶æ€
    â”œâ”€â”€ raw-targets/               # ç”Ÿæˆçš„åŸå§‹ä»£ç 
    â”œâ”€â”€ fixed-targets/             # ä¿®å¤åçš„ä»£ç 
    â”œâ”€â”€ code-coverage-reports/     # è¦†ç›–ç‡æŠ¥å‘Š
    â””â”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
```

---

## ğŸ” æŸ¥çœ‹è¿è¡Œç»“æœ

### 1. æ£€æŸ¥ç”Ÿæˆçš„ Fuzz Target

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç 
ls -lh results/output-cjson-cJSON_Parse/raw-targets/

# æŸ¥çœ‹å…·ä½“æ–‡ä»¶
cat results/output-cjson-cJSON_Parse/raw-targets/target_01.c
```

### 2. æŸ¥çœ‹ç¼–è¯‘ç»“æœ

```bash
# æŸ¥çœ‹çŠ¶æ€ç›®å½•
cat results/output-cjson-cJSON_Parse/status/status.txt
```

### 3. æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š

```bash
# æŸ¥çœ‹è¦†ç›–ç‡
ls results/output-cjson-cJSON_Parse/code-coverage-reports/
```

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. è®¤è¯é—®é¢˜

å¦‚æœä½¿ç”¨ Vertex AIï¼Œéœ€è¦å…ˆè®¾ç½® Google Cloud è®¤è¯ï¼š

```bash
# è®¾ç½®è®¤è¯
gcloud auth application-default login

# è®¾ç½®é¡¹ç›®
gcloud config set project YOUR_PROJECT_ID
```

### 2. æ¨¡å‹ä¸å¯ç”¨

æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹
python3 -c "from llm_toolkit import models; print(models.LLM.all_llm_names())"
```

### 3. è¶…æ—¶é—®é¢˜

å¢åŠ è¶…æ—¶æ—¶é—´ï¼š

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  --run-timeout 300  # 5åˆ†é’Ÿ
```

---

## ğŸ“Š Workflow æ‰§è¡Œæµç¨‹

LangGraph workflow çš„æ‰§è¡Œæµç¨‹ï¼š

```
1. Supervisor (è·¯ç”±å†³ç­–)
   â†“
2. FunctionAnalyzer (åˆ†æå‡½æ•°)
   â†“
3. Supervisor (å†³å®šä¸‹ä¸€æ­¥)
   â†“
4. Prototyper (ç”Ÿæˆä»£ç )
   â†“
5. Supervisor (å†³å®šä¸‹ä¸€æ­¥)
   â†“
6. Build (ç¼–è¯‘)
   â†“
7. Supervisor (å†³å®šä¸‹ä¸€æ­¥)
   â†“
8. Execution (è¿è¡Œ)
   â†“
9. å¦‚æœæœ‰é—®é¢˜ â†’ Enhancer/CrashAnalyzer
   â†“
10. é‡å¤ç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
```

---

## ğŸ”¬ é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰å·¥ä½œç›®å½•

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  -w ./my-custom-results
```

### 2. æŒ‡å®š OSS-Fuzz ç›®å½•

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  --oss-fuzz-dir /path/to/oss-fuzz
```

### 3. ä½¿ç”¨ä¸åŒçš„ temperature

```bash
python3 agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse \
  --model vertex_ai_gemini-2-5-pro-chat \
  --temperature 0.7
```

---

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡è¿è¡Œ**: ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½ OSS-Fuzz å’Œç›¸å…³ä¾èµ–ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
2. **å¹¶è¡Œè¿è¡Œ**: é¿å…åŒæ—¶è¿è¡Œå¤ªå¤šå®éªŒï¼Œå¯èƒ½è¶…å‡º LLM API é…é¢
3. **æ—¥å¿—çº§åˆ«**: ä½¿ç”¨ `-v` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•
4. **ç»“æœä¿å­˜**: æ‰€æœ‰ä¸­é—´ç»“æœéƒ½ä¼šä¿å­˜ï¼Œå¯ä»¥éšæ—¶ä¸­æ–­å’Œæ¢å¤

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LangGraph æ¶æ„è¯„ä¼°](docs/ARCHITECTURE_ASSESSMENT.md)
- [Agent Graph README](agent_graph/README.md)
- [OSS-Fuzz é¡¹ç›®è®¾ç½®](Usage.md)
- [ä¼˜åŒ–è·¯çº¿å›¾](docs/OPTIMIZATION_ROADMAP.md)

---

**ç¥æµ‹è¯•é¡ºåˆ©ï¼** ğŸ‰

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚

