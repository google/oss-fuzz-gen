# LogicFuzz

**Automated Fuzz Target Generation using LLM Agents**

LogicFuzz is an intelligent fuzzing framework that leverages Large Language Models (LLMs) to automatically generate high-quality fuzz targets. It uses a **two-phase agentic workflow** to achieve high compilation success rates and maximize code coverage.

---

## ğŸ¯ Key Features

- **ğŸ¤– AI-Powered Generation**: Uses LLM agents to analyze functions and generate fuzz targets
- **ğŸ“Š High Success Rate**: 70-85% compilation success through intelligent error fixing
- **ğŸ”„ Iterative Improvement**: Automatically optimizes coverage and discovers real bugs
- **ğŸ›¡ï¸ Robust Workflow**: Two-phase design with multi-layer protection against failures
- **âš¡ Token Efficient**: Optimized prompts with 80% token reduction
- **ğŸ” FI Integration**: Leverages Fuzz Introspector for enhanced context and better generation quality

**Supported Models:**
- OpenAI GPT (gpt-4, gpt-5)
- Vertex AI Gemini (gemini-2-5-pro-chat)

---

## ğŸ“š Documentation

- **[NEW_PROJECT_SETUP.md](docs/NEW_PROJECT_SETUP.md)** - Complete guide for setting up new projects (private repos, custom codebases)
- **[SIGNATURE_FIX_README.md](docs/SIGNATURE_FIX_README.md)** - Function signature extraction and fixing
- **[Usage.md](Usage.md)** - OSS-Fuzz project quick setup guide
- **[Data Preparation](data_prep/README.md)** - Benchmark YAML generation

---

## ğŸš€ Quick Start

### Basic Usage

```bash
# Run with default settings
python agent_graph/main.py -y conti-benchmark/cjson.yaml --model gpt-5

# Run with specific function
python agent_graph/main.py -y conti-benchmark/cjson.yaml \
  -f cJSON_Parse --model gpt-5

# Run with Fuzz Introspector context (recommended for better results)
# Note: First launch FI server in a separate terminal - see "With Local FI" section below
python agent_graph/main.py -y conti-benchmark/conti-cmp/mosh.yaml -l gpt-5 -n 5 --context -e http://0.0.0.0:8080/api 2>&1 |tee logicfuzz-1029.log

# Run with custom options
python agent_graph/main.py -y conti-benchmark/cjson.yaml \
  --model gpt-5 \
  --context --max-iterations 5 --run-timeout 600
```

### Alternative Entry Point

```bash
# Using run_logicfuzz.py (equivalent to above)
python run_logicfuzz.py --agent -y conti-benchmark/cjson.yaml --model gpt-5
```

---

## ğŸ“ Architecture Overview

LogicFuzz uses a **Supervisor-Agent Pattern** with multi-agent collaboration:

### ğŸ§  Two-Phase Workflow

**Phase 1: COMPILATION** â†’ Get the code to compile successfully
- Function Analyzer â†’ Prototyper â†’ Build â†’ Enhancer (up to 3 retries)

**Phase 2: OPTIMIZATION** â†’ Maximize coverage and find bugs  
- Execution â†’ Crash/Coverage Analysis â†’ Enhancer â†’ Iterate

### ğŸ¤– Key Agents

- ğŸ”µ **Supervisor** - Central router deciding next action
- ğŸŸ¡ **Function Analyzer** - Analyzes API semantics and constraints
- ğŸŸ¡ **Prototyper** - Generates fuzz target code
- ğŸŸ¡ **Enhancer** - Fixes errors and improves coverage
- ğŸ”´ **Crash/Context Analyzer** - Validates real bugs vs false positives
- ğŸ”´ **Coverage Analyzer** - Suggests optimization strategies
- ğŸŸ£ **Build/Execution** - Compiles and runs fuzzer

### ğŸ§  Session Memory

Agents share knowledge through **Session Memory**:
- API constraints and usage patterns
- Known error fixes
- Coverage optimization strategies

ğŸ“– **For detailed workflow diagrams and agent details, see [agent_graph/README.md](agent_graph/README.md)**

---

## ğŸ“ Project Structure

```
logicfuzz/
â”œâ”€â”€ agent_graph/          # LangGraph workflow & agents
â”‚   â”œâ”€â”€ workflow.py       # Workflow orchestration
â”‚   â”œâ”€â”€ nodes/           # Agent implementations
â”‚   â””â”€â”€ prompts/         # LLM system prompts
â”œâ”€â”€ conti-benchmark/     # Benchmark YAML files
â”œâ”€â”€ run_logicfuzz.py    # Main runner
â””â”€â”€ run_single_fuzz.py  # Single execution
```

---

## ğŸ“ Usage Examples

### Single Function
```bash
python agent_graph/main.py \
  -y conti-benchmark/libxml2.yaml \
  -f xmlParseDocument \
  --model gpt-5
```

### Multiple Trials
```bash
python agent_graph/main.py \
  -y conti-benchmark/cjson.yaml \
  --model gpt-5 \
  -n 5
```

### With Fuzz Introspector (Recommended)

For better results, use Fuzz Introspector context:

```bash
# Terminal 1: Start FI server
bash report/launch_local_introspector.sh

# Terminal 2: Run with FI context
python agent_graph/main.py \
  -y conti-benchmark/mosh.yaml \
  --model gpt-5 \
  --context \
  -e http://0.0.0.0:8080/api
```

### New Project Setup

See **[NEW_PROJECT_SETUP.md](docs/NEW_PROJECT_SETUP.md)** for complete guide on testing your own projects

---

\* "Total project lines" measures the source code of the project-under-test compiled and linked by the preexisting human-written fuzz targets from OSS-Fuzz.

\* "Total coverage gain" is calculated using a denominator of the "Total project lines". "Total relative gain" is the increase in coverage compared to the old number of covered lines.

\* Additional code from the project-under-test maybe included when compiling the new fuzz targets and result in high percentage gains.
